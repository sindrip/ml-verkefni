{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genres = {'reggae': 0, 'metal': 1, 'blues': 2, 'country': 3,\n",
    "         'classical': 4, 'pop': 5, 'jazz': 6, 'rock': 7,\n",
    "         'hiphop': 8, 'disco': 9}\n",
    "#Genres\n",
    "# 0: reggae\n",
    "# 1: metal\n",
    "# 2: blues\n",
    "# 3: country\n",
    "# 4: classical\n",
    "# 5: pop\n",
    "# 6: jazz\n",
    "# 7: rock\n",
    "# 8: hiphop\n",
    "# 9: disco\n",
    "\n",
    "def_rate = 22050\n",
    "\n",
    "def readSongs(duration):\n",
    "    pathlist = Path('../genres').glob('**/*.wav')\n",
    "    \n",
    "    song_sigs = {'reggae': [], 'metal': [], 'blues': [], 'country': [],\n",
    "         'classical': [], 'pop': [], 'jazz': [], 'rock': [],\n",
    "         'hiphop': [], 'disco': []}\n",
    "    \n",
    "    train_sigs = copy.deepcopy(song_sigs)\n",
    "    test_sigs = copy.deepcopy(song_sigs)\n",
    "    \n",
    "    for path in pathlist:\n",
    "        p = str(path)\n",
    "        genre = p.split('/')[2]\n",
    "        (rate, sig) = wav.read(p)\n",
    "        sig = sig[:rate*duration]\n",
    "        song_sigs[genre].append(sig)\n",
    "    \n",
    "    for key in song_sigs:\n",
    "        perm = np.random.permutation(100)\n",
    "        train = perm[:70]\n",
    "        test = perm[70:]\n",
    "        \n",
    "        train_sigs[key] = np.array(song_sigs[key])[train]\n",
    "        test_sigs[key] = np.array(song_sigs[key])[test]\n",
    "    return train_sigs, test_sigs\n",
    "\n",
    "def extractFeatures(signals, sample_len):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for key in signals:\n",
    "        for sig in signals[key]:\n",
    "            no_samples = int((len(sig)/def_rate)/sample_len)\n",
    "            part_len = int(def_rate*sample_len)\n",
    "            for i in range(no_samples):\n",
    "                part = sig[i*part_len:(i+1)*part_len]\n",
    "                mfcc_feat = mfcc(part, def_rate, nfft=551)\n",
    "                d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "                dd_mfcc_feat = delta(d_mfcc_feat, 2)\n",
    "                \n",
    "                #Cast to single vector\n",
    "                sample = np.hstack((np.hstack((mfcc_feat.flatten(), d_mfcc_feat.flatten())), dd_mfcc_feat.flatten()))\n",
    "                features.append(sample)\n",
    "                labels.append(genres[key])\n",
    "                \n",
    "    return features, labels\n",
    "\n",
    "def getData(duration, sample_len):\n",
    "    train_signal, test_signal = readSongs(duration)\n",
    "    \n",
    "    train_feat, train_label = extractFeatures(train_signal, sample_len)\n",
    "    test_feat, test_label = extractFeatures(test_signal, sample_len)\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(train_feat)\n",
    "    train_feat = scaler.transform(train_feat)\n",
    "    test_feat = scaler.transform(test_feat)\n",
    "    \n",
    "    return train_feat, train_label, test_feat, test_label, scaler\n",
    "\n",
    "def createForest(duration, sample_len):\n",
    "    trf, trl, tef, tel, scaler = getData(duration, sample_len)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_jobs=-1, n_estimators=500, max_features='sqrt', oob_score=True)\n",
    "    rf.fit(trf, trl)\n",
    "    \n",
    "    return rf, scaler, tef, tel\n",
    "\n",
    "def songWeightedPred(rf, feat, label, no_samples):\n",
    "    truth = []\n",
    "    pred = []\n",
    "    for i in range(int(feat.shape[0]/no_samples)):\n",
    "        truth.append(label[i*no_samples])\n",
    "        \n",
    "        pr = rf.predict_proba(feat[i*no_samples:(i+1)*no_samples,:])\n",
    "        pr = np.sum(pr, axis=0)/no_samples\n",
    "        pred.append(np.argmax(pr))\n",
    "    return truth, pred\n",
    "\n",
    "def testModel(duration, sample_len):\n",
    "    rf, scaler, tef, tel = createForest(duration, sample_len)\n",
    "    \n",
    "    tar_names = list(genres.keys())\n",
    "    pred = rf.predict(tef)\n",
    "    print(confusion_matrix(tel, pred))\n",
    "    print(classification_report(tel, pred, target_names=tar_names))\n",
    "          \n",
    "    tr, pr = songWeightedPred(rf, tef, tel, int(duration/sample_len))\n",
    "    print(np.where(tr==np.array(pr))[0].shape[0]/300)\n",
    "\n",
    "    print(confusion_matrix(tr, pr))\n",
    "    print(classification_report(tr, pr, target_names=tar_names))\n",
    "    return rf, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 28/0.05 =================\n",
      "[[ 5109   516  1190  1645   551  2447  1063   558  2440  1281]\n",
      " [  254 13847   485    84    34   256   197   641   429   573]\n",
      " [ 1086  1905  8820   989   671     9  1608   732   342   638]\n",
      " [ 1227  1027  2084  5090  1077  1304  1580  1830   404  1177]\n",
      " [  363    83   206   342 14108    43  1097   344    36   178]\n",
      " [  515    83    19   629   208 12664   398   310  1196   778]\n",
      " [  735   424  1502  1257  3275   370  7658   787   299   493]\n",
      " [ 1145  2030  2123  2131   709  1441  1025  3106   534  2556]\n",
      " [ 1248  2007  1133   564   238  2799   458   536  5746  2071]\n",
      " [  938  1252   585  1383   447  4669   764  1350   933  4479]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     reggae       0.40      0.30      0.35     16800\n",
      "      metal       0.60      0.82      0.69     16800\n",
      "      blues       0.49      0.53      0.50     16800\n",
      "    country       0.36      0.30      0.33     16800\n",
      "  classical       0.66      0.84      0.74     16800\n",
      "        pop       0.49      0.75      0.59     16800\n",
      "       jazz       0.48      0.46      0.47     16800\n",
      "       rock       0.30      0.18      0.23     16800\n",
      "     hiphop       0.46      0.34      0.39     16800\n",
      "      disco       0.31      0.27      0.29     16800\n",
      "\n",
      "avg / total       0.46      0.48      0.46    168000\n",
      "\n",
      "0.6633333333333333\n",
      "[[15  1  2  2  0  5  0  0  4  1]\n",
      " [ 0 29  0  0  0  0  1  0  0  0]\n",
      " [ 0  4 23  0  1  0  2  0  0  0]\n",
      " [ 0  1  1 18  0  4  1  5  0  0]\n",
      " [ 0  0  0  0 30  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 30  0  0  0  0]\n",
      " [ 0  0  1  0  4  1 23  0  0  1]\n",
      " [ 2  2  7  3  0  4  1  7  0  4]\n",
      " [ 2  3  3  0  0  6  0  0 14  2]\n",
      " [ 0  1  1  0  0 15  0  2  1 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     reggae       0.79      0.50      0.61        30\n",
      "      metal       0.71      0.97      0.82        30\n",
      "      blues       0.61      0.77      0.68        30\n",
      "    country       0.78      0.60      0.68        30\n",
      "  classical       0.86      1.00      0.92        30\n",
      "        pop       0.46      1.00      0.63        30\n",
      "       jazz       0.82      0.77      0.79        30\n",
      "       rock       0.50      0.23      0.32        30\n",
      "     hiphop       0.74      0.47      0.57        30\n",
      "      disco       0.56      0.33      0.42        30\n",
      "\n",
      "avg / total       0.68      0.66      0.64       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=============== 28/28 =================')\n",
    "testModel(28, 28)\n",
    "print('\\n\\n\\n\\n')\n",
    "print('=============== 28/14 =================')\n",
    "testModel(28, 14)\n",
    "print('\\n\\n\\n\\n')\n",
    "print('=============== 25/5 =================')\n",
    "testModel(25, 5)\n",
    "print('\\n\\n\\n\\n')\n",
    "print('=============== 27/3 =================')\n",
    "testModel(27, 3)\n",
    "print('\\n\\n\\n\\n')\n",
    "print('=============== 28/2 =================')\n",
    "testModel(28, 2)\n",
    "print('\\n\\n\\n\\n')\n",
    "print('=============== 28/1 =================')\n",
    "testModel(28, 1)\n",
    "print('\\n\\n\\n\\n')\n",
    "print('=============== 28/0.5 =================')\n",
    "testModel(28, 0.5)\n",
    "print('\\n\\n\\n\\n')\n",
    "print('=============== 28/0.25 =================')\n",
    "testModel(28, 0.25)\n",
    "print('\\n\\n\\n\\n')\n",
    "print('=============== 28/0.05 =================')\n",
    "rf, scaler = testModel(28, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[0 3 6 9]\n",
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "[ 0  1  2  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "sample_len = 3\n",
    "y = np.arange(sample_len)\n",
    "x = np.array([0,1,2,3])\n",
    "print(x)\n",
    "x = x*3\n",
    "print(x)\n",
    "\n",
    "fun = lambda x: print(x)\n",
    "t = list(map(lambda x: x + y, x))\n",
    "print(np.array(t))\n",
    "te_idx = [0,3]\n",
    "\n",
    "new = np.array(t)[te_idx]\n",
    "print(new.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "no_samples = 2\n",
    "signals = [0,1,2,3]\n",
    "list_len = np.arange(no_samples)\n",
    "\n",
    "t = np.array(list(map(lambda x: x + list_len, np.arange(len(signals)))))\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45 0.25 0.35]\n",
      " [0.4  0.5  0.6 ]]\n",
      "[0 2]\n"
     ]
    }
   ],
   "source": [
    "def avgNSamples(a, N=2):\n",
    "    tmp = np.cumsum(a, 0)[N-1::N]/float(N)\n",
    "    tmp[1:] = tmp[1:] - tmp[:-1]\n",
    "    return tmp\n",
    "\n",
    "x = np.array([[0.7,0.2,0.3], [0.2,0.3,0.4], [0.4,0.5,0.6], [0.4,0.5,0.6]])\n",
    "t = avgNSamples(x)\n",
    "print(t)\n",
    "print(np.argmax(t, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4]\n"
     ]
    }
   ],
   "source": [
    "t = [1,2,3,4,5,6]\n",
    "print(t[::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
